# ABE Drift Demo — Alibi Detect (Tabular)

A script-only workflow to detect **data drift in tabular features** using **Alibi Detect**.  
It compares a **reference** dataset to several **current** datasets and writes concise JSON/CSV artifacts ready for dashboards or a custom UI.

---

## 1. What’s included

- `src/run_alibi_tabular.py`  
  Runs feature-level drift tests with `TabularDrift` over:
  - `data/ref_emb.parquet` (reference)
  - `data/cur_*.parquet` (current variants: clean / brightness / blur / rotation / noise)
  - Produces:
    - `reports/alibi_tabular/summary.json` — dataset-level summary per run
    - `reports/alibi_tabular/per_feature.csv` — p-values & drift flags by feature
    - `reports/alibi_tabular/runs/<name>.json` — one JSON per comparison

> Assumes each parquet file contains **numeric** columns: `emb_0 … emb_49` (50 dims) and `weight`.

---

## 2. Setup

### 2.1 Environment

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

pip install -r requirements.txt
```

### 2.2 Input data

Ensure the following parquet files exist in `data/`:

```
data/
 ├─ ref_emb.parquet
 ├─ cur_clean_emb.parquet
 ├─ cur_brightness_emb.parquet
 ├─ cur_blur_emb.parquet
 ├─ cur_rotation_emb.parquet
 └─ cur_noise_emb.parquet
```

Each file contains numeric columns:
- `emb_0 … emb_49`
- `weight`

---

## 3. Run drift detection

```bash
python src/run_alibi_tabular.py
```

Artifacts are written to:

```
reports/
 └─ alibi_tabular/
    ├─ summary.json
    ├─ per_feature.csv
    └─ runs/
       ├─ clean.json
       ├─ brightness.json
       ├─ blur.json
       ├─ rotation.json
       └─ noise.json
```

---

## 4. Reading the results

Console output (example):

```
=== BRIGHTNESS ===
Dataset drift: True | global p=NA | alpha=0.05 | drifted 51/51 (100.00%)
  weight p-value: 0 | drift=True
```

- **Dataset drift** — `True` if any feature drifted after multiple-testing correction.
- **alpha** — significance level (default 0.05) after `bonferroni`.
- **drifted X/51** — number/share of drifted features (50 embeddings + `weight`).
- **weight p-value** — KS test p-value for the `weight` feature.

Typical outcomes with the demo data:
- **clean**: only `weight` drifts (due to a +10% shift).
- **brightness / blur / noise**: most or all embedding dimensions drift (≈ 51/51).
- **rotation**: strong, often ~48/51.

---

## 5. Script behavior & options

- **Multiple-testing correction**: `"bonferroni"` (can switch to `"fdr"`).
- **Drift mode**: feature-level (`drift_type="feature"`).  
  Change to `"batch"` in the script if a single batch-level test is preferred.
- **Categoricals**: If you add categorical columns, encode them and pass
  `categories_per_feature={feature_index: cardinality}` to `TabularDrift(...)`
  (Chi-square for categoricals, KS for numeric).
- **Version robustness**: The script handles API differences across Alibi Detect versions
  (e.g., positional vs keyword `X_ref`, array vs scalar fields).

---

## 6. Troubleshooting

- **“None of PyTorch, TensorFlow, or Flax have been found…”**  
  Benign for classic tabular tests. Install a backend only if you use neural encoders:
  - TensorFlow: `pip install "alibi-detect[tensorflow]"`
  - PyTorch: `pip install "alibi-detect[torch]"`

- **`ValueError: The truth value of an array with more than one element is ambiguous`**  
  Occurs if casting `bool(data["is_drift"])` when it’s an array. The provided script aggregates safely with `any()`.

- **`TypeError: TabularDrift.__init__() got an unexpected keyword argument 'X_ref'`**  
  Some versions expect **positional** `X_ref`. The script tries both signatures automatically.

- **`UserWarning: No categories_per_feature ... KSDrift will be applied`**  
  Safe to ignore if all features are numeric.

- **Over-sensitivity**  
  Keep reference/current windows comparable; KS can trip easily if `ref` is huge and `current` is tiny.

---

## 7. Extending

- Add CLI flags for `--data-dir`, `--out-dir`, thresholds, and correction type.
- Export Prometheus-friendly counters (drift share, per-feature flags).
- Build a Streamlit UI to visualize `summary.json` and `per_feature.csv`.

---

## 8. License & attribution

- Uses **Alibi Detect** (Apache 2.0).
- Parquet inputs are typically generated by your data-prep scripts (e.g., Evidently demo).
- Scripts are provided “as is” for internal demos and can be adapted to ABE.
